{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COs_-Y1xOKeJ"
      },
      "source": [
        "### Running Your Code in Colab\n",
        "\n",
        "We recommend you develop locally and then use Colab to run your code. You'll need to upload the code to drive.\n",
        "\n",
        "For experiments with a batch size greater than one, use the T4 GPU in order to see a *significant* speedup. This is crucial in order to run the experiments in a reasonable amount of time.\n",
        "\n",
        "Make sure to [download](https://drive.google.com/file/d/1mECKLG3NWH9uwFgAYRIdAKrABbTGkbVq/view?usp=sharing) the full training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0X2yjR1bI5C4",
        "outputId": "1d900dc9-8aa8-4fcc-85be-ba56a15abc7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount your drive to access files in your Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oRpmUnlJJRyG",
        "outputId": "9a91e359-973b-4782-c033-745c05042413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/stuff/10601-HW7\n"
          ]
        }
      ],
      "source": [
        "# cd into the directory where your code is\n",
        "# e.g. %cd /content/drive/MyDrive/cmu/10-301/hw7/handout\n",
        "%cd /content/drive/MyDrive/stuff/10601-HW7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tkzoe79LPmX1"
      },
      "outputs": [],
      "source": [
        "# Set your data paths. Change this if the data is in a different location\n",
        "tiny_train_stories = \"data/tiny_train_stories.json\"\n",
        "tiny_valid_stories = \"data/tiny_valid_stories.json\"\n",
        "\n",
        "full_train_stories = \"data/HW7_large_stories/train_stories.json\"\n",
        "full_valid_stories = \"data/HW7_large_stories/valid_stories.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4Whb8pdGOMU"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ign1vlA-c1lG",
        "outputId": "a495a946-50bd-491b-fbb5-5969f23b6b94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing SelfAttention Test Case 1...Passed\n",
            ".Testing SelfAttention Test Case 2...Passed\n",
            ".Testing RNN Test Case 1...Passed\n",
            ".Testing RNN Test Case 2...Passed\n",
            ".Testing RNNCell Test Case 1...Passed\n",
            ".Testing RNNCell Test Case 2...Passed\n",
            ".Using device: cuda\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/stuff/10601-HW7/test_rnn.py\", line 221, in <module>\n",
            "    unittest.main()\n",
            "  File \"/usr/lib/python3.10/unittest/main.py\", line 101, in __init__\n",
            "    self.runTests()\n",
            "  File \"/usr/lib/python3.10/unittest/main.py\", line 271, in runTests\n",
            "    self.result = testRunner.run(self.test)\n",
            "  File \"/usr/lib/python3.10/unittest/runner.py\", line 184, in run\n",
            "    test(result)\n",
            "  File \"/usr/lib/python3.10/unittest/suite.py\", line 84, in __call__\n",
            "    return self.run(*args, **kwds)\n",
            "  File \"/usr/lib/python3.10/unittest/suite.py\", line 122, in run\n",
            "    test(result)\n",
            "  File \"/usr/lib/python3.10/unittest/suite.py\", line 84, in __call__\n",
            "    return self.run(*args, **kwds)\n",
            "  File \"/usr/lib/python3.10/unittest/suite.py\", line 122, in run\n",
            "    test(result)\n",
            "  File \"/usr/lib/python3.10/unittest/case.py\", line 650, in __call__\n",
            "    return self.run(*args, **kwds)\n",
            "  File \"/usr/lib/python3.10/unittest/case.py\", line 591, in run\n",
            "    self._callTestMethod(testMethod)\n",
            "  File \"/usr/lib/python3.10/unittest/case.py\", line 549, in _callTestMethod\n",
            "    method()\n",
            "  File \"/content/drive/MyDrive/stuff/10601-HW7/test_rnn.py\", line 217, in test_train\n",
            "    rnn.main(args)\n",
            "  File \"/content/drive/MyDrive/stuff/10601-HW7/rnn.py\", line 586, in main\n",
            "    tokenizer = AutoTokenizer.from_pretrained(\"my_tokenizer\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\", line 920, in from_pretrained\n",
            "    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 2213, in from_pretrained\n",
            "    return cls._from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 2428, in _from_pretrained\n",
            "    tokenizer_file_handle = json.load(tokenizer_file_handle)\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 293, in load\n",
            "    return loads(fp.read(),\n",
            "  File \"/usr/lib/python3.10/codecs.py\", line 319, in decode\n",
            "    def decode(self, input, final=False):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python test_rnn.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iwfiNlt_GNpI",
        "outputId": "4602a7bb-5004-45a5-b6e5-d053b0a2a186",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "RNNLanguageModel(\n",
            "  (embeddings): Embedding(1024, 64)\n",
            "  (rnn): RNN(\n",
            "    (cell): RNNCell(\n",
            "      (i2h): Linear(in_features=64, out_features=128, bias=True)\n",
            "      (h2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "    (out): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (attention): SelfAttention(\n",
            "    (query_transform): Linear(in_features=128, out_features=32, bias=True)\n",
            "    (key_transform): Linear(in_features=128, out_features=32, bias=True)\n",
            "    (value_transform): Linear(in_features=128, out_features=32, bias=True)\n",
            "    (output_transform): Linear(in_features=32, out_features=128, bias=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=128, out_features=1024, bias=True)\n",
            ")\n",
            "Number of Parameters:  255584\n",
            "Loading data\n",
            "Finished Loading Dataset\n",
            "Batch: 0 | Sequence Length: 128 | Elapsed time (minutes): 1.9e-05\n",
            "Batch: 1 | Sequence Length: 128 | Elapsed time (minutes): 0.012847\n",
            "Batch: 2 | Sequence Length: 128 | Elapsed time (minutes): 0.026584\n",
            "Batch: 3 | Sequence Length: 128 | Elapsed time (minutes): 0.037957\n",
            "Batch: 4 | Sequence Length: 128 | Elapsed time (minutes): 0.049105\n",
            "Batch: 5 | Sequence Length: 128 | Elapsed time (minutes): 0.061741\n",
            "Batch: 6 | Sequence Length: 128 | Elapsed time (minutes): 0.071987\n",
            "Batch: 7 | Sequence Length: 128 | Elapsed time (minutes): 0.080582\n",
            "Batch: 8 | Sequence Length: 128 | Elapsed time (minutes): 0.089925\n",
            "Batch: 9 | Sequence Length: 128 | Elapsed time (minutes): 0.099785\n",
            "Batch: 10 | Sequence Length: 128 | Elapsed time (minutes): 0.111853\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python rnn.py --train_data {tiny_train_stories} --val_data {tiny_valid_stories} --embed_dim 64 --hidden_dim 128 --train_losses_out train_loss.txt --val_losses_out valid_loss.txt --metrics_out metrics.txt --dk 32 --dv 32 --num_sequences 128 --batch_size 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y89FUa-7Mru"
      },
      "source": [
        "#### 5.1\n",
        "\n",
        "Uncomment the corresponding `embed_hidden_dims`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8msmm2XCKveG",
        "outputId": "1a7cc033-1e21-4589-93a5-5220e520e4c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "RNNLanguageModel(\n",
            "  (embeddings): Embedding(1024, 64)\n",
            "  (rnn): RNN(\n",
            "    (cell): RNNCell(\n",
            "      (i2h): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (h2h): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "    (out): Linear(in_features=64, out_features=64, bias=True)\n",
            "  )\n",
            "  (attention): SelfAttention(\n",
            "    (query_transform): Linear(in_features=64, out_features=128, bias=True)\n",
            "    (key_transform): Linear(in_features=64, out_features=128, bias=True)\n",
            "    (value_transform): Linear(in_features=64, out_features=128, bias=True)\n",
            "    (output_transform): Linear(in_features=128, out_features=64, bias=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=64, out_features=1024, bias=True)\n",
            ")\n",
            "Number of Parameters:  177792\n",
            "Loading data\n",
            "Finished Loading Dataset\n",
            "Batch: 0 | Sequence Length: 128 | Elapsed time (minutes): 0.000243\n",
            "Batch: 39 | Sequence Length: 128 | Elapsed time (minutes): 0.23683\n",
            "Batch: 78 | Sequence Length: 128 | Elapsed time (minutes): 0.440652\n",
            "Batch: 117 | Sequence Length: 128 | Elapsed time (minutes): 0.639923\n",
            "Batch: 156 | Sequence Length: 128 | Elapsed time (minutes): 0.846339\n",
            "Batch: 195 | Sequence Length: 128 | Elapsed time (minutes): 1.052249\n",
            "Batch: 234 | Sequence Length: 128 | Elapsed time (minutes): 1.261421\n",
            "Batch: 273 | Sequence Length: 128 | Elapsed time (minutes): 1.472097\n",
            "Batch: 312 | Sequence Length: 128 | Elapsed time (minutes): 1.67749\n",
            "Batch: 351 | Sequence Length: 128 | Elapsed time (minutes): 1.894333\n",
            "Train Batch Losses: [6.958001, 5.720809, 4.948858, 4.75718, 4.323444, 4.129498, 4.043581, 3.959246, 3.847002, 3.784828]\n",
            "Train Losses [6.958001, 5.720809, 4.948858, 4.75718, 4.323444, 4.129498, 4.043581, 3.959246, 3.847002, 3.784828]\n",
            "Valid Losses [6.940027, 7.121208, 7.200302, 7.711006, 9.574274, 11.00391, 11.987489, 12.640615, 13.80047, 13.995452]\n",
            "Final Train Loss 3.784828\n",
            "Final Valid Loss 13.995452\n",
            "Time 126.06009197235107\n",
            "Final Train Loss:  3.784828\n",
            "Final Valid Loss:  13.995452\n"
          ]
        }
      ],
      "source": [
        "embed_hidden_dims = 64\n",
        "# embed_hidden_dims = 128\n",
        "# embed_hidden_dims = 256\n",
        "# embed_hidden_dims = 512\n",
        "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim {embed_hidden_dims} --hidden_dim {embed_hidden_dims} --train_losses_out train_losses_51_64.txt --val_losses_out val_losses_51_64.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences 50000 --batch_size 128"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#embed_hidden_dims = 64\n",
        "embed_hidden_dims = 128\n",
        "# embed_hidden_dims = 256\n",
        "# embed_hidden_dims = 512\n",
        "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim {embed_hidden_dims} --hidden_dim {embed_hidden_dims} --train_losses_out train_losses_51_128.txt --val_losses_out val_losses_51_128.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences 50000 --batch_size 128"
      ],
      "metadata": {
        "id": "0B3Ou-s8Qg1y",
        "outputId": "d57f0081-717f-4093-e715-875618ed15ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "RNNLanguageModel(\n",
            "  (embeddings): Embedding(1024, 128)\n",
            "  (rnn): RNN(\n",
            "    (cell): RNNCell(\n",
            "      (i2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (h2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "    (out): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (attention): SelfAttention(\n",
            "    (query_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (key_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (value_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (output_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=128, out_features=1024, bias=True)\n",
            ")\n",
            "Number of Parameters:  378752\n",
            "Loading data\n",
            "Finished Loading Dataset\n",
            "Batch: 0 | Sequence Length: 128 | Elapsed time (minutes): 1.6e-05\n",
            "Batch: 39 | Sequence Length: 128 | Elapsed time (minutes): 0.230774\n",
            "Batch: 78 | Sequence Length: 128 | Elapsed time (minutes): 0.453219\n",
            "Batch: 117 | Sequence Length: 128 | Elapsed time (minutes): 0.676984\n",
            "Batch: 156 | Sequence Length: 128 | Elapsed time (minutes): 0.900752\n",
            "Batch: 195 | Sequence Length: 128 | Elapsed time (minutes): 1.11882\n",
            "Batch: 234 | Sequence Length: 128 | Elapsed time (minutes): 1.35331\n",
            "Batch: 273 | Sequence Length: 128 | Elapsed time (minutes): 1.58979\n",
            "Batch: 312 | Sequence Length: 128 | Elapsed time (minutes): 1.809674\n",
            "Batch: 351 | Sequence Length: 128 | Elapsed time (minutes): 2.028907\n",
            "Train Batch Losses: [6.943843, 5.459865, 4.8011, 4.306326, 4.024395, 3.878591, 3.784671, 3.703665, 3.611405, 3.582852]\n",
            "Train Losses [6.943843, 5.459865, 4.8011, 4.306326, 4.024395, 3.878591, 3.784671, 3.703665, 3.611405, 3.582852]\n",
            "Valid Losses [6.929395, 7.161088, 7.87005, 10.719877, 13.110335, 14.949716, 15.81617, 16.356773, 17.730291, 17.619659]\n",
            "Final Train Loss 3.582852\n",
            "Final Valid Loss 17.619659\n",
            "Time 134.81162643432617\n",
            "Final Train Loss:  3.582852\n",
            "Final Valid Loss:  17.619659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#embed_hidden_dims = 64\n",
        "# embed_hidden_dims = 128\n",
        "embed_hidden_dims = 256\n",
        "# embed_hidden_dims = 512\n",
        "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim {embed_hidden_dims} --hidden_dim {embed_hidden_dims} --train_losses_out train_losses_51_256.txt --val_losses_out val_losses_51_256.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences 50000 --batch_size 128"
      ],
      "metadata": {
        "id": "JvmnPYz4Qguf",
        "outputId": "ce3578b7-a9b8-4e1c-a136-e1c2b899a09b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "RNNLanguageModel(\n",
            "  (embeddings): Embedding(1024, 256)\n",
            "  (rnn): RNN(\n",
            "    (cell): RNNCell(\n",
            "      (i2h): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (h2h): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "    (out): Linear(in_features=256, out_features=256, bias=True)\n",
            "  )\n",
            "  (attention): SelfAttention(\n",
            "    (query_transform): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (key_transform): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (value_transform): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (output_transform): Linear(in_features=128, out_features=256, bias=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=256, out_features=1024, bias=True)\n",
            ")\n",
            "Number of Parameters:  854400\n",
            "Loading data\n",
            "Finished Loading Dataset\n",
            "Batch: 0 | Sequence Length: 128 | Elapsed time (minutes): 1.4e-05\n",
            "Batch: 39 | Sequence Length: 128 | Elapsed time (minutes): 0.339556\n",
            "Batch: 78 | Sequence Length: 128 | Elapsed time (minutes): 0.670493\n",
            "Batch: 117 | Sequence Length: 128 | Elapsed time (minutes): 0.997062\n",
            "Batch: 156 | Sequence Length: 128 | Elapsed time (minutes): 1.326248\n",
            "Batch: 195 | Sequence Length: 128 | Elapsed time (minutes): 1.651247\n",
            "Batch: 234 | Sequence Length: 128 | Elapsed time (minutes): 1.978989\n",
            "Batch: 273 | Sequence Length: 128 | Elapsed time (minutes): 2.305475\n",
            "Batch: 312 | Sequence Length: 128 | Elapsed time (minutes): 2.631915\n",
            "Batch: 351 | Sequence Length: 128 | Elapsed time (minutes): 2.959146\n",
            "Train Batch Losses: [6.944245, 5.253613, 4.54622, 4.014059, 3.747787, 3.585888, 3.497437, 3.407653, 3.295304, 3.255796]\n",
            "Train Losses [6.944245, 5.253613, 4.54622, 4.014059, 3.747787, 3.585888, 3.497437, 3.407653, 3.295304, 3.255796]\n",
            "Valid Losses [6.932828, 7.612255, 10.395938, 14.665602, 17.209478, 17.444929, 17.476002, 17.382132, 18.233191, 18.142275]\n",
            "Final Train Loss 3.255796\n",
            "Final Valid Loss 18.142275\n",
            "Time 197.26400017738342\n",
            "Final Train Loss:  3.255796\n",
            "Final Valid Loss:  18.142275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#embed_hidden_dims = 64\n",
        "# embed_hidden_dims = 128\n",
        "# embed_hidden_dims = 256\n",
        "embed_hidden_dims = 512\n",
        "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim {embed_hidden_dims} --hidden_dim {embed_hidden_dims} --train_losses_out train_losses_51_512.txt --val_losses_out val_losses_51_512.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences 50000 --batch_size 128"
      ],
      "metadata": {
        "id": "phCUfwHZQggt",
        "outputId": "4636854f-9c63-40e7-8c9c-5633ee8d553b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "RNNLanguageModel(\n",
            "  (embeddings): Embedding(1024, 512)\n",
            "  (rnn): RNN(\n",
            "    (cell): RNNCell(\n",
            "      (i2h): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (h2h): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "    (out): Linear(in_features=512, out_features=512, bias=True)\n",
            "  )\n",
            "  (attention): SelfAttention(\n",
            "    (query_transform): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (key_transform): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (value_transform): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (output_transform): Linear(in_features=128, out_features=512, bias=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=512, out_features=1024, bias=True)\n",
            ")\n",
            "Number of Parameters:  2100608\n",
            "Loading data\n",
            "Finished Loading Dataset\n",
            "Batch: 0 | Sequence Length: 128 | Elapsed time (minutes): 1.5e-05\n",
            "Batch: 39 | Sequence Length: 128 | Elapsed time (minutes): 0.570004\n",
            "Batch: 78 | Sequence Length: 128 | Elapsed time (minutes): 1.125143\n",
            "Batch: 117 | Sequence Length: 128 | Elapsed time (minutes): 1.676557\n",
            "Batch: 156 | Sequence Length: 128 | Elapsed time (minutes): 2.231763\n",
            "Batch: 195 | Sequence Length: 128 | Elapsed time (minutes): 2.785175\n",
            "Batch: 234 | Sequence Length: 128 | Elapsed time (minutes): 3.338791\n",
            "Batch: 273 | Sequence Length: 128 | Elapsed time (minutes): 3.892607\n",
            "Batch: 312 | Sequence Length: 128 | Elapsed time (minutes): 4.448657\n",
            "Batch: 351 | Sequence Length: 128 | Elapsed time (minutes): 5.002182\n",
            "Train Batch Losses: [6.930358, 5.116224, 4.12226, 3.652977, 3.401239, 3.244764, 3.141551, 3.049818, 2.919954, 2.87951]\n",
            "Train Losses [6.930358, 5.116224, 4.12226, 3.652977, 3.401239, 3.244764, 3.141551, 3.049818, 2.919954, 2.87951]\n",
            "Valid Losses [6.93526, 7.949926, 10.744236, 12.494746, 13.651983, 14.069904, 14.423675, 14.859895, 15.714396, 16.208719]\n",
            "Final Train Loss 2.87951\n",
            "Final Valid Loss 16.208719\n",
            "Time 333.3177111148834\n",
            "Final Train Loss:  2.87951\n",
            "Final Valid Loss:  16.208719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ4fn9YDAmiW"
      },
      "source": [
        "#### 5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Vh5lsRTuApFD",
        "outputId": "01637754-f098-408e-8a41-2ad2b1e70f38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "RNNLanguageModel(\n",
            "  (embeddings): Embedding(1024, 128)\n",
            "  (rnn): RNN(\n",
            "    (cell): RNNCell(\n",
            "      (i2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (h2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "    (out): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (attention): SelfAttention(\n",
            "    (query_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (key_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (value_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (output_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=128, out_features=1024, bias=True)\n",
            ")\n",
            "Number of Parameters:  378752\n",
            "Loading data\n",
            "Finished Loading Dataset\n",
            "Batch: 0 | Sequence Length: 128 | Elapsed time (minutes): 1.4e-05\n",
            "Batch: 156 | Sequence Length: 128 | Elapsed time (minutes): 0.804181\n",
            "Batch: 312 | Sequence Length: 128 | Elapsed time (minutes): 1.607139\n",
            "Batch: 468 | Sequence Length: 128 | Elapsed time (minutes): 2.406755\n",
            "Batch: 624 | Sequence Length: 128 | Elapsed time (minutes): 3.218351\n",
            "Batch: 780 | Sequence Length: 128 | Elapsed time (minutes): 4.022916\n",
            "Batch: 936 | Sequence Length: 128 | Elapsed time (minutes): 4.816921\n",
            "Batch: 1092 | Sequence Length: 128 | Elapsed time (minutes): 5.612956\n",
            "Batch: 1248 | Sequence Length: 128 | Elapsed time (minutes): 6.417323\n",
            "Batch: 1404 | Sequence Length: 128 | Elapsed time (minutes): 7.226546\n",
            "Batch: 1560 | Sequence Length: 128 | Elapsed time (minutes): 8.035121\n",
            "Train Batch Losses: [6.945277, 4.73407, 3.815213, 3.544329, 3.418227, 3.330533, 3.274652, 3.213446, 3.111132, 3.094153, 3.060249]\n",
            "Train Losses [6.945277, 4.73407, 3.815213, 3.544329, 3.418227, 3.330533, 3.274652, 3.213446, 3.111132, 3.094153, 3.060249]\n",
            "Valid Losses [6.930208, 10.132702, 13.265343, 13.846433, 14.729315, 14.747498, 14.452321, 14.99731, 14.848339, 15.023118, 14.918139]\n",
            "Final Train Loss 3.060249\n",
            "Final Valid Loss 14.918139\n",
            "Time 482.7601912021637\n",
            "Final Train Loss:  3.060249\n",
            "Final Valid Loss:  14.918139\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "# batch_size = 64\n",
        "# batch_size = 128\n",
        "# batch_size = 256\n",
        "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim 128 --hidden_dim 128 --train_losses_out 52_32_train_losses.txt --val_losses_out 52_32_val_losses.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences 50000 --batch_size {batch_size}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch_size = 32\n",
        "batch_size = 64\n",
        "# batch_size = 128\n",
        "# batch_size = 256\n",
        "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim 128 --hidden_dim 128 --train_losses_out 52_64_train_losses.txt --val_losses_out 52_64_val_losses.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences 50000 --batch_size {batch_size}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKmwmVtDSgw7",
        "outputId": "6aa7a1d8-a600-4499-9ea1-91d45847486b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "RNNLanguageModel(\n",
            "  (embeddings): Embedding(1024, 128)\n",
            "  (rnn): RNN(\n",
            "    (cell): RNNCell(\n",
            "      (i2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (h2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "    (out): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (attention): SelfAttention(\n",
            "    (query_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (key_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (value_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (output_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=128, out_features=1024, bias=True)\n",
            ")\n",
            "Number of Parameters:  378752\n",
            "Loading data\n",
            "Finished Loading Dataset\n",
            "Batch: 0 | Sequence Length: 128 | Elapsed time (minutes): 1.7e-05\n",
            "Batch: 78 | Sequence Length: 128 | Elapsed time (minutes): 0.419103\n",
            "Batch: 156 | Sequence Length: 128 | Elapsed time (minutes): 0.824445\n",
            "Batch: 234 | Sequence Length: 128 | Elapsed time (minutes): 1.23176\n",
            "Batch: 312 | Sequence Length: 128 | Elapsed time (minutes): 1.6379\n",
            "Batch: 390 | Sequence Length: 128 | Elapsed time (minutes): 2.042497\n",
            "Batch: 468 | Sequence Length: 128 | Elapsed time (minutes): 2.43561\n",
            "Batch: 546 | Sequence Length: 128 | Elapsed time (minutes): 2.836486\n",
            "Batch: 624 | Sequence Length: 128 | Elapsed time (minutes): 3.260676\n",
            "Batch: 702 | Sequence Length: 128 | Elapsed time (minutes): 3.668262\n",
            "Batch: 780 | Sequence Length: 128 | Elapsed time (minutes): 4.075282\n",
            "Train Batch Losses: [6.94456, 5.167518, 4.224183, 3.834532, 3.654972, 3.538589, 3.455323, 3.384986, 3.280588, 3.261498, 3.237302]\n",
            "Train Losses [6.94456, 5.167518, 4.224183, 3.834532, 3.654972, 3.538589, 3.455323, 3.384986, 3.280588, 3.261498, 3.237302]\n",
            "Valid Losses [6.929583, 7.805657, 11.107706, 13.605138, 13.82409, 13.917233, 14.26061, 14.569043, 14.999469, 15.408575, 15.317883]\n",
            "Final Train Loss 3.237302\n",
            "Final Valid Loss 15.317883\n",
            "Time 244.8916416168213\n",
            "Final Train Loss:  3.237302\n",
            "Final Valid Loss:  15.317883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch_size = 32\n",
        "#batch_size = 64\n",
        "batch_size = 128\n",
        "# batch_size = 256\n",
        "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim 128 --hidden_dim 128 --train_losses_out 52_128_train_losses.txt --val_losses_out 52_128_val_losses.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences 50000 --batch_size {batch_size}"
      ],
      "metadata": {
        "id": "zD3h2Tn7SixZ",
        "outputId": "25d16dfb-442b-4587-e6bb-14daa5935a9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "RNNLanguageModel(\n",
            "  (embeddings): Embedding(1024, 128)\n",
            "  (rnn): RNN(\n",
            "    (cell): RNNCell(\n",
            "      (i2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (h2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "    (out): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (attention): SelfAttention(\n",
            "    (query_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (key_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (value_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (output_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=128, out_features=1024, bias=True)\n",
            ")\n",
            "Number of Parameters:  378752\n",
            "Loading data\n",
            "Finished Loading Dataset\n",
            "Batch: 0 | Sequence Length: 128 | Elapsed time (minutes): 1.5e-05\n",
            "Batch: 39 | Sequence Length: 128 | Elapsed time (minutes): 0.235569\n",
            "Batch: 78 | Sequence Length: 128 | Elapsed time (minutes): 0.450719\n",
            "Batch: 117 | Sequence Length: 128 | Elapsed time (minutes): 0.668501\n",
            "Batch: 156 | Sequence Length: 128 | Elapsed time (minutes): 0.885125\n",
            "Batch: 195 | Sequence Length: 128 | Elapsed time (minutes): 1.102704\n",
            "Batch: 234 | Sequence Length: 128 | Elapsed time (minutes): 1.319119\n",
            "Batch: 273 | Sequence Length: 128 | Elapsed time (minutes): 1.536161\n",
            "Batch: 312 | Sequence Length: 128 | Elapsed time (minutes): 1.752468\n",
            "Batch: 351 | Sequence Length: 128 | Elapsed time (minutes): 1.969469\n",
            "Train Batch Losses: [6.943843, 5.459865, 4.8011, 4.306326, 4.024395, 3.878591, 3.784671, 3.703665, 3.611405, 3.582852]\n",
            "Train Losses [6.943843, 5.459865, 4.8011, 4.306326, 4.024395, 3.878591, 3.784671, 3.703665, 3.611405, 3.582852]\n",
            "Valid Losses [6.929395, 7.161088, 7.87005, 10.719877, 13.110335, 14.949716, 15.81617, 16.356773, 17.730291, 17.619659]\n",
            "Final Train Loss 3.582852\n",
            "Final Valid Loss 17.619659\n",
            "Time 131.14621305465698\n",
            "Final Train Loss:  3.582852\n",
            "Final Valid Loss:  17.619659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "# batch_size = 64\n",
        "# batch_size = 128\n",
        "batch_size = 256\n",
        "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim 128 --hidden_dim 128 --train_losses_out 52_256_train_losses.txt --val_losses_out 52_256_val_losses.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences 50000 --batch_size {batch_size}"
      ],
      "metadata": {
        "id": "QQpsoGpMSi-f",
        "outputId": "c7ee2c34-c81a-4b41-e968-d36136474822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "RNNLanguageModel(\n",
            "  (embeddings): Embedding(1024, 128)\n",
            "  (rnn): RNN(\n",
            "    (cell): RNNCell(\n",
            "      (i2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (h2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "    (out): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (attention): SelfAttention(\n",
            "    (query_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (key_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (value_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (output_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=128, out_features=1024, bias=True)\n",
            ")\n",
            "Number of Parameters:  378752\n",
            "Loading data\n",
            "Finished Loading Dataset\n",
            "Batch: 0 | Sequence Length: 128 | Elapsed time (minutes): 1.8e-05\n",
            "Batch: 19 | Sequence Length: 128 | Elapsed time (minutes): 0.183312\n",
            "Batch: 38 | Sequence Length: 128 | Elapsed time (minutes): 0.351254\n",
            "Batch: 57 | Sequence Length: 128 | Elapsed time (minutes): 0.522192\n",
            "Batch: 76 | Sequence Length: 128 | Elapsed time (minutes): 0.693642\n",
            "Batch: 95 | Sequence Length: 128 | Elapsed time (minutes): 0.868003\n",
            "Batch: 114 | Sequence Length: 128 | Elapsed time (minutes): 1.035628\n",
            "Batch: 133 | Sequence Length: 128 | Elapsed time (minutes): 1.205233\n",
            "Batch: 152 | Sequence Length: 128 | Elapsed time (minutes): 1.374565\n",
            "Batch: 171 | Sequence Length: 128 | Elapsed time (minutes): 1.543345\n",
            "Batch: 190 | Sequence Length: 128 | Elapsed time (minutes): 1.711261\n",
            "Train Batch Losses: [6.943286, 5.912946, 4.997382, 4.895177, 4.704659, 4.415464, 4.191173, 4.049447, 3.939798, 3.893917, 3.836843]\n",
            "Train Losses [6.943286, 5.912946, 4.997382, 4.895177, 4.704659, 4.415464, 4.191173, 4.049447, 3.939798, 3.893917, 3.836843]\n",
            "Valid Losses [6.929378, 7.118953, 7.143244, 7.503143, 8.098345, 9.649147, 11.362152, 12.82538, 13.962823, 14.246463, 14.980657]\n",
            "Final Train Loss 3.836843\n",
            "Final Valid Loss 14.980657\n",
            "Time 105.57277989387512\n",
            "Final Train Loss:  3.836843\n",
            "Final Valid Loss:  14.980657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3-FuxQlB8TI"
      },
      "source": [
        "#### 5.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YtltQa_uB9a_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2203aa2-bb59-4c74-c281-679f07f59216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "RNNLanguageModel(\n",
            "  (embeddings): Embedding(1024, 128)\n",
            "  (rnn): RNN(\n",
            "    (cell): RNNCell(\n",
            "      (i2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (h2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "    (out): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (attention): SelfAttention(\n",
            "    (query_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (key_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (value_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (output_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=128, out_features=1024, bias=True)\n",
            ")\n",
            "Number of Parameters:  378752\n",
            "Loading data\n",
            "Finished Loading Dataset\n",
            "Batch: 0 | Sequence Length: 128 | Elapsed time (minutes): 1.5e-05\n",
            "Batch: 7 | Sequence Length: 128 | Elapsed time (minutes): 0.068427\n",
            "Batch: 14 | Sequence Length: 128 | Elapsed time (minutes): 0.106111\n",
            "Batch: 21 | Sequence Length: 128 | Elapsed time (minutes): 0.143986\n",
            "Batch: 28 | Sequence Length: 128 | Elapsed time (minutes): 0.181531\n",
            "Batch: 35 | Sequence Length: 128 | Elapsed time (minutes): 0.219688\n",
            "Batch: 42 | Sequence Length: 128 | Elapsed time (minutes): 0.263493\n",
            "Batch: 49 | Sequence Length: 128 | Elapsed time (minutes): 0.308546\n",
            "Batch: 56 | Sequence Length: 128 | Elapsed time (minutes): 0.34691\n",
            "Batch: 63 | Sequence Length: 128 | Elapsed time (minutes): 0.385088\n",
            "Batch: 70 | Sequence Length: 128 | Elapsed time (minutes): 0.423391\n",
            "Batch: 77 | Sequence Length: 128 | Elapsed time (minutes): 0.463767\n",
            "Train Batch Losses: [6.943844, 6.548826, 5.852883, 5.133769, 5.04327, 4.982386, 4.970234, 4.899476, 4.868873, 4.822446, 4.754554, 4.640236]\n",
            "Train Losses [6.943844, 6.548826, 5.852883, 5.133769, 5.04327, 4.982386, 4.970234, 4.899476, 4.868873, 4.822446, 4.754554, 4.640236]\n",
            "Valid Losses [6.929395, 7.252704, 7.24407, 7.148297, 7.100014, 7.152088, 7.226175, 7.320151, 7.430017, 7.536475, 7.676946, 7.862556]\n",
            "Final Train Loss 4.640236\n",
            "Final Valid Loss 7.862556\n",
            "Time 28.32127809524536\n",
            "Final Train Loss:  4.640236\n",
            "Final Valid Loss:  7.862556\n"
          ]
        }
      ],
      "source": [
        "num_sequences = 10000\n",
        "# num_sequences = 20000\n",
        "# num_sequences = 50000\n",
        "# num_sequences = 100000\n",
        "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim 128 --hidden_dim 128 --train_losses_out 53_10000_train_losses.txt --val_losses_out 53_10000_val_losses.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences {num_sequences} --batch_size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hWEQ0VZiStsO",
        "outputId": "b4871573-0cb4-4070-89da-2bfd08a5a0de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "RNNLanguageModel(\n",
            "  (embeddings): Embedding(1024, 128)\n",
            "  (rnn): RNN(\n",
            "    (cell): RNNCell(\n",
            "      (i2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (h2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "    (out): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (attention): SelfAttention(\n",
            "    (query_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (key_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (value_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (output_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=128, out_features=1024, bias=True)\n",
            ")\n",
            "Number of Parameters:  378752\n",
            "Loading data\n",
            "Finished Loading Dataset\n",
            "Batch: 0 | Sequence Length: 128 | Elapsed time (minutes): 1.4e-05\n",
            "Batch: 15 | Sequence Length: 128 | Elapsed time (minutes): 0.099915\n",
            "Batch: 30 | Sequence Length: 128 | Elapsed time (minutes): 0.187896\n",
            "Batch: 45 | Sequence Length: 128 | Elapsed time (minutes): 0.268343\n",
            "Batch: 60 | Sequence Length: 128 | Elapsed time (minutes): 0.360957\n",
            "Batch: 75 | Sequence Length: 128 | Elapsed time (minutes): 0.441656\n",
            "Batch: 90 | Sequence Length: 128 | Elapsed time (minutes): 0.52391\n",
            "Batch: 105 | Sequence Length: 128 | Elapsed time (minutes): 0.615421\n",
            "Batch: 120 | Sequence Length: 128 | Elapsed time (minutes): 0.696156\n",
            "Batch: 135 | Sequence Length: 128 | Elapsed time (minutes): 0.789066\n",
            "Batch: 150 | Sequence Length: 128 | Elapsed time (minutes): 0.870477\n",
            "Train Batch Losses: [6.943844, 6.13667, 5.067395, 4.963831, 4.860316, 4.733363, 4.482824, 4.296358, 4.150698, 4.043362, 4.018165]\n",
            "Train Losses [6.943844, 6.13667, 5.067395, 4.963831, 4.860316, 4.733363, 4.482824, 4.296358, 4.150698, 4.043362, 4.018165]\n",
            "Valid Losses [6.929395, 7.160149, 7.124006, 7.23362, 7.499089, 7.762976, 8.542634, 9.68412, 11.154631, 12.291363, 12.505713]\n",
            "Final Train Loss 4.018165\n",
            "Final Valid Loss 12.505713\n",
            "Time 54.21397566795349\n",
            "Final Train Loss:  4.018165\n",
            "Final Valid Loss:  12.505713\n"
          ]
        }
      ],
      "source": [
        "# num_sequences = 10000\n",
        "num_sequences = 20000\n",
        "# num_sequences = 50000\n",
        "# num_sequences = 100000\n",
        "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim 128 --hidden_dim 128 --train_losses_out 53_20000_train_losses.txt --val_losses_out 53_20000_val_losses.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences {num_sequences} --batch_size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "egPIpREmSuLS",
        "outputId": "70a5930a-1739-486d-fed9-3506d171d28b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "RNNLanguageModel(\n",
            "  (embeddings): Embedding(1024, 128)\n",
            "  (rnn): RNN(\n",
            "    (cell): RNNCell(\n",
            "      (i2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (h2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "    (out): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (attention): SelfAttention(\n",
            "    (query_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (key_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (value_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (output_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=128, out_features=1024, bias=True)\n",
            ")\n",
            "Number of Parameters:  378752\n",
            "Loading data\n",
            "Finished Loading Dataset\n",
            "Batch: 0 | Sequence Length: 128 | Elapsed time (minutes): 2e-05\n",
            "Batch: 39 | Sequence Length: 128 | Elapsed time (minutes): 0.229975\n",
            "Batch: 78 | Sequence Length: 128 | Elapsed time (minutes): 0.447191\n",
            "Batch: 117 | Sequence Length: 128 | Elapsed time (minutes): 0.665539\n",
            "Batch: 156 | Sequence Length: 128 | Elapsed time (minutes): 0.883587\n",
            "Batch: 195 | Sequence Length: 128 | Elapsed time (minutes): 1.107938\n",
            "Batch: 234 | Sequence Length: 128 | Elapsed time (minutes): 1.333098\n",
            "Batch: 273 | Sequence Length: 128 | Elapsed time (minutes): 1.551\n",
            "Batch: 312 | Sequence Length: 128 | Elapsed time (minutes): 1.768444\n",
            "Batch: 351 | Sequence Length: 128 | Elapsed time (minutes): 1.98762\n",
            "Train Batch Losses: [6.943843, 5.459865, 4.8011, 4.306326, 4.024395, 3.878591, 3.784671, 3.703664, 3.611405, 3.582852]\n",
            "Train Losses [6.943843, 5.459865, 4.8011, 4.306326, 4.024395, 3.878591, 3.784671, 3.703664, 3.611405, 3.582852]\n",
            "Valid Losses [6.929395, 7.161088, 7.87005, 10.719877, 13.110335, 14.949716, 15.81617, 16.356773, 17.730291, 17.619659]\n",
            "Final Train Loss 3.582852\n",
            "Final Valid Loss 17.619659\n",
            "Time 132.33568334579468\n",
            "Final Train Loss:  3.582852\n",
            "Final Valid Loss:  17.619659\n"
          ]
        }
      ],
      "source": [
        "#num_sequences = 10000\n",
        "# num_sequences = 20000\n",
        "num_sequences = 50000\n",
        "# num_sequences = 100000\n",
        "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim 128 --hidden_dim 128 --train_losses_out 53_50000_train_losses.txt --val_losses_out 53_50000_val_losses.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences {num_sequences} --batch_size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "za3e0akASuYf",
        "outputId": "729a2b95-eb06-402a-ef69-51ff5bc3fea6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "RNNLanguageModel(\n",
            "  (embeddings): Embedding(1024, 128)\n",
            "  (rnn): RNN(\n",
            "    (cell): RNNCell(\n",
            "      (i2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (h2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (activation): ReLU()\n",
            "    )\n",
            "    (out): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (attention): SelfAttention(\n",
            "    (query_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (key_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (value_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (output_transform): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=128, out_features=1024, bias=True)\n",
            ")\n",
            "Number of Parameters:  378752\n",
            "Loading data\n",
            "Finished Loading Dataset\n",
            "Batch: 0 | Sequence Length: 128 | Elapsed time (minutes): 1.4e-05\n",
            "Batch: 78 | Sequence Length: 128 | Elapsed time (minutes): 0.451161\n",
            "Batch: 156 | Sequence Length: 128 | Elapsed time (minutes): 0.888729\n",
            "Batch: 234 | Sequence Length: 128 | Elapsed time (minutes): 1.323452\n",
            "Batch: 312 | Sequence Length: 128 | Elapsed time (minutes): 1.757998\n",
            "Batch: 390 | Sequence Length: 128 | Elapsed time (minutes): 2.193355\n",
            "Batch: 468 | Sequence Length: 128 | Elapsed time (minutes): 2.629486\n",
            "Batch: 546 | Sequence Length: 128 | Elapsed time (minutes): 3.064919\n",
            "Batch: 624 | Sequence Length: 128 | Elapsed time (minutes): 3.517197\n",
            "Batch: 702 | Sequence Length: 128 | Elapsed time (minutes): 3.95423\n",
            "Batch: 780 | Sequence Length: 128 | Elapsed time (minutes): 4.390752\n",
            "Train Batch Losses: [6.943844, 5.130482, 4.165361, 3.831631, 3.657535, 3.562475, 3.44387, 3.343643, 3.273505, 3.213735, 3.194913]\n",
            "Train Losses [6.943844, 5.130482, 4.165361, 3.831631, 3.657535, 3.562475, 3.44387, 3.343643, 3.273505, 3.213735, 3.194913]\n",
            "Valid Losses [6.929395, 7.87005, 13.110335, 15.81617, 17.730291, 17.898422, 18.459047, 18.443174, 18.82004, 19.108021, 19.730089]\n",
            "Final Train Loss 3.194913\n",
            "Final Valid Loss 19.730089\n",
            "Time 263.84956192970276\n",
            "Final Train Loss:  3.194913\n",
            "Final Valid Loss:  19.730089\n"
          ]
        }
      ],
      "source": [
        "# num_sequences = 10000\n",
        "# num_sequences = 20000\n",
        "# num_sequences = 50000\n",
        "num_sequences = 100000\n",
        "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim 128 --hidden_dim 128 --train_losses_out 53_100000_train_losses.txt --val_losses_out 53_100000_val_losses.txt --metrics_out metrics.txt --dk 128 --dv 128 --num_sequences {num_sequences} --batch_size 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iwe2VRiEjO2"
      },
      "source": [
        "#### 5.4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtMCKtcJEkZ0"
      },
      "outputs": [],
      "source": [
        "!python rnn.py --train_data {full_train_stories} --val_data {full_valid_stories} --embed_dim 512 --hidden_dim 512 --train_losses_out train_losses.txt --val_losses_out val_losses.txt --metrics_out metrics.txt --dk 256 --dv 256 --num_sequences 250000 --batch_size 128"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mjx7nhaZTyt6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VOBghpM8T0OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = {\n",
        "    64: 'train_losses_51_64.txt',\n",
        "    128: 'train_losses_51_128.txt',\n",
        "    256: 'train_losses_51_256.txt',\n",
        "    512: 'train_losses_51_512.txt'\n",
        "}"
      ],
      "metadata": {
        "id": "sN9I3EpowSmg",
        "outputId": "c41de3af-9073-420d-8c64-0674b58cd8fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 2) (<ipython-input-1-d998cc55eb01>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-d998cc55eb01>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \"64train_losses_51_64\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rSBV6MVOwfdR"
      },
      "execution_count": 1,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}